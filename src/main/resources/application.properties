kafka.producer.bootstrap.servers=8.133.186.237:9092
#记录完整提交，最慢的但是最大可能的持久化
kafka.producer.acks=all
#请求失败重试的次数
kafka.producer.retries=3
kafka.producer.batch.size=16384
#默认情况即使缓冲区有剩余的空间，也会立即发送请求，设置一段时间用来等待从而将缓冲区填的更多，单位为毫秒，
#producer发送数据会延迟1ms，可以减少发送到kafka服务器的请求数据
kafka.producer.linger.ms=1
#提供给生产者缓冲内存总量
kafka.producer.buffer.memory=33554432
#序列化的方式
kafka.producer.key.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.producer.value.serialize=org.apache.kafka.common.serialization.StringSerializer


#metadata.broker.list=172.16.71.132:9092,172.16.71.133:9092,172.16.71.134:9092
#compression.codec=1
#group.id=kafkainput
#producer.type=sync
#max.message.size=1048576
#request.required.acks=0
#serializer.class=kafka.serializer.StringEncoder
#zookeeper.session.timeout.ms=1000000
#auto.offset.reset=latest
#enable.auto.commit=true
#key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#key.serializer=org.apache.kafka.common.serialization.StringSerializer
#value.serializer=org.apache.kafka.common.serialization.StringSerializer
#rebalance.max.retries=5
#rebalance.backoff.ms=1200
#max.poll.time=500
#max.poll.size=500000
#fetch.max.bytes=10485760
#max.poll.records=3000
#bootstrap.servers=172.16.71.132:9092,172.16.71.133:9092,172.16.71.134:9092