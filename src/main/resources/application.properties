kafka.producer.bootstrap.servers=8.133.186.237:9092
#kafka.producer.bootstrap.servers=172.16.71.132:9092,172.16.71.133:9092
#记录完整提交，最慢的但是最大可能的持久化
kafka.producer.acks=all
#请求失败重试的次数
kafka.producer.retries=3
kafka.producer.batch.size=16384
#默认情况即使缓冲区有剩余的空间，也会立即发送请求，设置一段时间用来等待从而将缓冲区填的更多，单位为毫秒，
#producer发送数据会延迟1ms，可以减少发送到kafka服务器的请求数据
kafka.producer.linger.ms=1
#提供给生产者缓冲内存总量
kafka.producer.buffer.memory=33554432
#序列化的方式
kafka.producer.key.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.producer.value.serializer=org.apache.kafka.common.serialization.StringSerializer


kafka.consumer.bootstrap.servers=8.133.186.237:9092
#kafka.consumer.bootstrap.servers=172.16.71.132:9092,172.16.71.133:9092
kafka.consumer.group.id=kafkaGroup
#，默认值为latest，表示自动将偏移重置为最新的偏移量
#可选的值为latest, earliest, none
kafka.consumer.auto.offset.reset=latest
#自动提交
kafka.consumer.enable.auto.commit=true
kafka.consumer.auto.commit.interval.ms=1000
#每次拉取数量
kafka.consumer.max.poll.records=3000
kafka.consumer.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafka.consumer.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

