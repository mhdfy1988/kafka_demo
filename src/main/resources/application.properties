#consumer.bootstrap.servers=8.133.186.237:9092
#consumer.bootstrap.servers=
#consumer.bootstrap.servers=
#consumer.bootstrap.servers=
#consumer.key.serializer=org.apache.kafka.common.serialization.StringSerializer
#consumer.value.serialize=org.apache.kafka.common.serialization.StringSerializer

#Properties props = new Properties();
#        props.put("bootstrap.servers", MQDict.MQ_ADDRESS_COLLECTION);
#        props.put("acks", "all");
#        props.put("retries", 0);
#        props.put("batch.size", 16384);
#        props.put("key.serializer", StringSerializer.class.getName());
#        props.put("value.serializer", StringSerializer.class.getName());
#————————————————
#版权声明：本文为CSDN博主「非琴不是筝」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
#原文链接：https://blog.csdn.net/feiqinbushizheng/article/details/89184144


#metadata.broker.list=172.16.71.132:9092,172.16.71.133:9092,172.16.71.134:9092
#compression.codec=1
#group.id=kafkainput
#producer.type=sync
#max.message.size=1048576
#request.required.acks=0
#serializer.class=kafka.serializer.StringEncoder
#zookeeper.session.timeout.ms=1000000
#auto.offset.reset=latest
#enable.auto.commit=true
#key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#key.serializer=org.apache.kafka.common.serialization.StringSerializer
#value.serializer=org.apache.kafka.common.serialization.StringSerializer
#rebalance.max.retries=5
#rebalance.backoff.ms=1200
#max.poll.time=500
#max.poll.size=500000
#fetch.max.bytes=10485760
#max.poll.records=3000
#bootstrap.servers=172.16.71.132:9092,172.16.71.133:9092,172.16.71.134:9092